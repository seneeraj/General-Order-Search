import streamlit as st
import fitz  # PyMuPDF
import re
from collections import defaultdict
from docx import Document  # for DOCX
import io

st.set_page_config(page_title="GO Explorer (Hindi Files)", layout="wide")
st.title("ЁЯУШ General Order Explorer (рд╣рд┐рдВрджреА рдЕрдзреНрдпрд╛рдп / рдирд┐рдпрдо рдЦреЛрдЬрдХ)")

uploaded_file = st.file_uploader("ЁЯУД Upload a Hindi PDF/DOCX", type=["pdf", "docx"])

# тЬЕ Configurable keywords
CHAPTER_KEYWORDS = ["рдЕрдзреНрдпрд╛рдп", "рднрд╛рдЧ", "рдЦрдВрдб", "рд╕реЗрдХреНрд╢рди"]
RULE_KEYWORDS = ["рдирд┐рдпрдо", "рдзрд╛рд░рд╛", "рдкреНрд░рд╛рд╡рдзрд╛рди"]

@st.cache_data(show_spinner=True)
def extract_text(file, filetype):
    if filetype == "pdf":
        doc = fitz.open(stream=file.read(), filetype="pdf")
        return "\n".join([page.get_text() for page in doc])
    elif filetype == "docx":
        doc = Document(io.BytesIO(file.read()))
        return "\n".join([para.text for para in doc.paragraphs])
    else:
        return ""

def build_chapter_pattern():
    """Build regex for chapters with multiple keywords"""
    patterns = []
    for k in CHAPTER_KEYWORDS:
        patterns.append(rf"{k}\s*[\dIVXреж-реп]+")  # e.g., рдЕрдзреНрдпрд╛рдп 1 / рднрд╛рдЧ II / рдЦрдВрдб рей
        patterns.append(rf"{k}\s*[рдкреНрд░рдердорджреНрд╡рд┐рддреАрдпрддреГрддреАрдпрдЪрддреБрд░реНрдердкрдЮреНрдЪрдо]+")  # e.g., рдЕрдзреНрдпрд╛рдп рдкреНрд░рдердо
    return "(" + "|".join(patterns) + ")"

def build_rule_pattern():
    """Build regex for rules with multiple keywords"""
    patterns = []
    for k in RULE_KEYWORDS:
        patterns.append(rf"{k}\s*[\dIVXреж-реп]+")  # e.g., рдирд┐рдпрдо 1 / рдзрд╛рд░рд╛ реи / рдкреНрд░рд╛рд╡рдзрд╛рди IV
        patterns.append(rf"{k}\s*рд╕рдВрдЦреНрдпрд╛\s*\d+")  # e.g., рдирд┐рдпрдо рд╕рдВрдЦреНрдпрд╛ 5
    return "(" + "|".join(patterns) + ")"

def parse_structure(text):
    structure = defaultdict(dict)

    # Compile patterns
    chapter_pattern = re.compile(build_chapter_pattern())
    rule_pattern = re.compile(build_rule_pattern())

    chapters = list(chapter_pattern.finditer(text))

    for i, chap in enumerate(chapters):
        chap_title = chap.group().strip()
        start = chap.end()
        end = chapters[i+1].start() if i+1 < len(chapters) else len(text)
        chap_text = text[start:end]

        rules = list(rule_pattern.finditer(chap_text))
        if not rules:
            structure[chap_title]["(рдХреЛрдИ рдирд┐рдпрдо/рдзрд╛рд░рд╛ рдирд╣реАрдВ рдорд┐рд▓рд╛)"] = chap_text.strip()
        else:
            for j, rule in enumerate(rules):
                rule_title = rule.group().strip()
                r_start = rule.end()
                r_end = rules[j+1].start() if j+1 < len(rules) else len(chap_text)
                rule_text = chap_text[r_start:r_end].strip()
                structure[chap_title][rule_title] = rule_text
    return structure

if uploaded_file:
    ext = uploaded_file.name.split(".")[-1].lower()
    text = extract_text(uploaded_file, ext)
    structure = parse_structure(text)

    chapters = list(structure.keys())
    if chapters:
        selected_chap = st.selectbox("ЁЯУЪ рдЕрдзреНрдпрд╛рдп / рднрд╛рдЧ / рдЦрдВрдб рдЪреБрдиреЗрдВ", chapters)
        if selected_chap:
            rules = list(structure[selected_chap].keys())
            selected_rule = st.selectbox("ЁЯУМ рдирд┐рдпрдо / рдзрд╛рд░рд╛ / рдкреНрд░рд╛рд╡рдзрд╛рди рдЪреБрдиреЗрдВ", rules)
            if selected_rule:
                st.markdown(f"### ЁЯУД {selected_rule}")
                st.text_area("ЁЯУЭ рд╡рд┐рд╡рд░рдг", structure[selected_chap][selected_rule], height=500)
    else:
        st.warning("тЭМ рдЕрдзреНрдпрд╛рдп/рднрд╛рдЧ/рдЦрдВрдб рдпрд╛ рдирд┐рдпрдо/рдзрд╛рд░рд╛/рдкреНрд░рд╛рд╡рдзрд╛рди рдирд╣реАрдВ рдорд┐рд▓рд╛ред рдХреГрдкрдпрд╛ рд╕рд╣реА рдпреВрдирд┐рдХреЛрдб рд╣рд┐рдВрджреА рдлрд╝рд╛рдЗрд▓ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВред")
